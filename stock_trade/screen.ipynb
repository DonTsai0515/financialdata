{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入套件\n",
    "import requests,json,datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "# 取得股票定價交易資訊\n",
    "def GetStockAfterHour(data,selectType):\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get('https://www.twse.com.tw/exchangeReport/BFT41U?response=json&date='+date+'&selectType='+selectType)\n",
    "    \n",
    "    # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        jcontent = json.loads(html.text)\n",
    "        data = jcontent['data']\n",
    "        data1=[[j.replace(',','') for j in i] for i in data if i[1]!='合計']\n",
    "        return data1\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "\n",
    "# 取得股票融資融券資訊\n",
    "def GetMarginTrade(date,selectType):\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get('https://www.twse.com.tw/exchangeReport/MI_MARGN?response=json&date='+date+'&selectType='+selectType)\n",
    "    \n",
    "    # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        jcontent = json.loads(html.text)\n",
    "        data = jcontent['data']\n",
    "        data1=[[j.replace(',','') for j in i] for i in data if i[1]!='合計']\n",
    "        return data1\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得股票融券借券資訊\n",
    "def GetCreditTrade(date):\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get('https://www.twse.com.tw/exchangeReport/TWT93U?response=json&date='+date)\n",
    "    \n",
    "     # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        jcontent = json.loads(html.text)\n",
    "        data = jcontent['data']\n",
    "        data1=[[j.replace(',','') for j in i] for i in data if i[1]!='合計']\n",
    "        return data1\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得三大法人彙總資訊( type參數分別是1外資,2自營商,3投信)\n",
    "def GetThreeMajor(date,type=3):\n",
    "    if type==1:\n",
    "        \n",
    "        # 外資彙總表\n",
    "        url = 'https://www.twse.com.tw/fund/TWT38U?response=json&date='+date\n",
    "    \n",
    "    elif type==2:\n",
    "        \n",
    "        # 自營商彙總表\n",
    "        url = 'https://www.twse.com.tw/fund/TWT43U?response=json&date='+date\n",
    "        \n",
    "    elif type==3:\n",
    "        \n",
    "        # 投信彙總表\n",
    "        url = 'https://www.twse.com.tw/fund/TWT44U?response=json&date='+date\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get(url)\n",
    "    \n",
    "    # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        jcontent = json.loads(html.text)\n",
    "        data = jcontent['data']\n",
    "        data1=[[j.replace(',','') for j in i] for i in data1]\n",
    "        return data1\n",
    "    \n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得熱門排行榜資訊\n",
    "def GetHotRank(t,e,n):\n",
    "    \n",
    "    # 網址\n",
    "    url = 'https://tw.stock.yahoo.com/d/i/rank.php?t='+t+'&e='+e+'&n='+n\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get(url)\n",
    "    \n",
    "    # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        \n",
    "        # 透過 BeautifulSoup 解析該網站\n",
    "        soup = BeautifulSoup(html.text,'html.parser')\n",
    "        \n",
    "        # 取得表格內資訊\n",
    "        rs_list = []\n",
    "        for tr in soup.find_all('tr',bgcolor='#ffffff'):\n",
    "            tr_context = [i.text.replace(',','') for i in tr.find_all('td')]\n",
    "            rs_list.append(tr_context)\n",
    "        return rs_list\n",
    "        \n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得外資熱門排行榜資訊(type參數分別是1單日買超排行,2上週買超排行,3單日賣超排行,4上週賣超排行)\n",
    "def GetForeignRank(type=1):\n",
    "    type=int(type)\n",
    "    if type == 1:\n",
    "        # 單日買超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/fgbuy_tse.html' \n",
    "    elif type == 2:\n",
    "        # 上週買超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/fgbuy_tse_w.html' \n",
    "    elif type == 3:\n",
    "        # 單日賣超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/fgsell_tse.html' \n",
    "    elif type == 4:\n",
    "        # 上週賣超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/fgsell_tse_w.html' \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    # 取得網站內容\n",
    "    html= requests.get(URL)\n",
    "\n",
    "    #成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        # 透過 BeautifulSoup 解析該網站\n",
    "        soup=BeautifulSoup(html.text,'html.parser')\n",
    "        # 取得表格內資訊\n",
    "        rs_list=[]\n",
    "        for tr in soup.find_all('tr',bgcolor='#FFFFFF'):\n",
    "            tr_content = [ i.text.replace(',','') for i in tr.find_all('td') ]\n",
    "            rs_list.append(tr_content)\n",
    "        return rs_list\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得自營商熱門排行榜資訊(type參數分別是1單日買超排行,2上週買超排行,3單日賣超排行,4上週賣超排行)\n",
    "def GetDealerRank(type=1):  \n",
    "    type=int(type)\n",
    "    if type == 1:\n",
    "        # 單日買超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/sebuy_tse.html'\n",
    "    elif type == 2:\n",
    "        # 上週買超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/sebuy_tse_w.html'\n",
    "    elif type == 3:\n",
    "        # 單日賣超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/sesell_tse.html'\n",
    "    elif type == 4:\n",
    "        # 上週賣超排行\n",
    "        URL='https://tw.stock.yahoo.com/d/i/sesell_tse_w.html'\n",
    "\n",
    "    # 取得網站內容\n",
    "    html= requests.get(URL)\n",
    "\n",
    "    #成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        # 透過 BeautifulSoup 解析該網站\n",
    "        soup=BeautifulSoup(html.text,'html.parser')\n",
    "        # 取得表格內資訊\n",
    "        rs_list=[]\n",
    "        for tr in soup.find_all('tr',bgcolor='#FFFFFF'):\n",
    "            tr_content = [ i.text.replace(',','') for i in tr.find_all('td') ]\n",
    "            rs_list.append(tr_content)\n",
    "        return rs_list\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 取得權值股資訊\n",
    "def GetWeightStock():\n",
    "    \n",
    "    # 網址\n",
    "    url = 'https://www.taifex.com.tw/cht/9/futuresQADetail'\n",
    "    \n",
    "    # 取得網站內容\n",
    "    html = requests.get(url)\n",
    "    \n",
    "    # 成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        # 透過 BeautifulSoup 解析該網站\n",
    "        soup = BeautifulSoup(html.text,'html.parser')\n",
    "        # 取得表格內資訊\n",
    "        rs_list = []\n",
    "        for tr in soup.find_all('tr',bgcolor='#FFFFFF'):\n",
    "            # 移除特殊符號\n",
    "            tr_context = [i.text.strip() for i in tr.find_all('td')]\n",
    "            # 取出前後兩個部分\n",
    "            first_stock = tr_context[:4]\n",
    "            last_stock = tr_context[4:8]\n",
    "            # 新增至統一的 List 中\n",
    "            rs_list.append(first_stock)\n",
    "            rs_list.append(last_stock)\n",
    "        rs_list = [ i for i in rs_list if i[0] != '']\n",
    "        rs_list.sort(key=lambda x : int(x[0]))\n",
    "        return rs_list\n",
    "    \n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "    \n",
    "# 將民國年日期轉換為西元年\n",
    "def ConvertYearFormat(YearStr):\n",
    "    tmpdate=YearStr.split('/')\n",
    "    return ''.join([str(int(tmpdate[0])+1911),tmpdate[1],tmpdate[2]])\n",
    "    \n",
    "# 取得股票日K線\n",
    "def GetStockDailyOHLC(date,stock_symbol):\n",
    "    # 取得網站內容\n",
    "    html= requests.get('https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date='+date+'&stockNo='+stock_symbol)\n",
    "    #成功取得網頁\n",
    "    if html.status_code == requests.codes.ok:\n",
    "        jcontent=json.loads(html.text)\n",
    "        if jcontent['stat'] == '很抱歉，沒有符合條件的資料!':\n",
    "            return []\n",
    "        else:\n",
    "            data=jcontent['data']\n",
    "            data1=[ [ j.replace(',','') for j in i ] for i in data ]\n",
    "            data2=[ [ConvertYearFormat(i[0]),float(i[3]),float(i[4]),float(i[5]),float(i[6]),float(i[1])/1000] for i in data1 ]\n",
    "            return data2\n",
    "    else:\n",
    "        print('爬蟲失敗')\n",
    "        return False\n",
    "        \n",
    "# 取得N日股票日K線\n",
    "def GetNumberStockDaily(num,stock_symbol):\n",
    "    currentTime= datetime.datetime.now()\n",
    "    rs=[]\n",
    "    while len(rs) <= num:\n",
    "        currentMonth=currentTime.strftime('%Y%m') \n",
    "        rs.extend(GetStockDailyOHLC(currentMonth+'01',stock_symbol))\n",
    "        while currentTime.strftime('%Y%m') == currentMonth:\n",
    "            currentTime -= datetime.timedelta(1)\n",
    "    rs.sort()\n",
    "    return rs[(num*-1):]\n",
    "\n",
    "# 取得股票日 K 線技術指標格式\n",
    "def GetTAStockDaily(num,stock_symbol):\n",
    "    KBar = GetNumberStockDaily(num,stock_symbol)\n",
    "    TAKBar = {}\n",
    "    TAKBar['time'] = [datetime.datetime.strptime(i[0],'%Y%m%d') for i in KBar]\n",
    "    TAKBar['open'] = [i[1] for i in KBar]   \n",
    "    TAKBar['high'] = [i[2] for i in KBar]\n",
    "    TAKBar['low'] = [i[3] for i in KBar] \n",
    "    TAKBar['close'] = [i[4] for i in KBar] \n",
    "    TAKBar['volume'] = [i[5] for i in KBar] \n",
    "    return TAKBar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
